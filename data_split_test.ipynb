{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/oscar/Desktop/Exjobb/Data/ieee_supplement/Hyperspectral_Grids/Salinas/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import visdom\n",
    "import utils\n",
    "import seaborn as sns\n",
    "from datasets import get_dataset, HyperX\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_values = [\"Undefined\", \"Brocoli_green_weeds_1\", \"Brocoli_green_weeds_2\", \"Fallow\",\n",
    "                        \"Fallow_rough_plow\", \"Fallow_smooth\", \"Stubble\",\n",
    "                        \"Celery\", \"Grapes_untrained\", \"Soil_vinyard_develop\",\n",
    "                        \"Corn_senesced_green_weeds\", \"Lettuce_romaine_4wk\", \"Lettuce_romaine_5wk\",\n",
    "                        \"Lettuce_romaine_6wk\", \"Lettuce_romaine_7wk\", \"Vinyard_untrained\",\n",
    "                        \"Vinyard_vertical_trellis\"]\n",
    "\n",
    "palette = None\n",
    "rgb_bands = (43, 21, 11)\n",
    "\n",
    "if palette is None:\n",
    "    # Generate color palette\n",
    "    palette = {0: (0, 0, 0)}\n",
    "    for k, color in enumerate(sns.color_palette(\"hls\", len(label_values) - 1)):\n",
    "        palette[k + 1] = tuple(np.asarray(255 * np.array(color), dtype='uint8'))\n",
    "invert_palette = {v: k for k, v in palette.items()}\n",
    "\n",
    "def convert_to_color(x):\n",
    "    return utils.convert_to_color_(x, palette=palette)\n",
    "def convert_from_color(x):\n",
    "    return utils.convert_from_color_(x, palette=invert_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_patches = np.zeros(int((len(os.listdir(data_path + '/salinas_fold_0/'))-3)/2))\n",
    "#train_gt = np.copy(train_patches)\n",
    "\n",
    "train_patches = []\n",
    "train_gt = []\n",
    "\n",
    "for i in (range(int((len(os.listdir(data_path + '/salinas_fold_0/'))-3)/2))):\n",
    "    #train_patches[i] = np.load(data_path + '/salinas_fold_0/patch_{}.npy'.format(i))\n",
    "    #train_gt[i] = np.load(data_path + '/salinas_fold_0/patch_{}_gt.npy'.format(i))\n",
    "    \n",
    "    train_patches.append(np.load(data_path + '/salinas_fold_0/patch_{}.npy'.format(i)))\n",
    "    train_gt.append(np.load(data_path + '/salinas_fold_0/patch_{}_gt.npy'.format(i)))\n",
    "\n",
    "test = np.load(data_path + '/salinas_fold_0/test.npy')\n",
    "test_gt = np.load(data_path + '/salinas_fold_0/test_gt.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones_like(train_gt)\n",
    "print(np.count_nonzero(mask))\n",
    "for i in range(len(mask)):\n",
    "    mask[i, train_gt[i] == 0] = 0\n",
    "print(np.count_nonzero(mask))\n",
    "p,x,y = np.nonzero(mask)\n",
    "print(str(p) + ' ' + str(x) + '' + str(y))\n",
    "p_u, x_u, y_u = np.nonzero(mask==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_np = np.array(train_gt)\n",
    "train_np = np.array(train_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = set()\n",
    "\n",
    "while len(idx) < 0.05*np.prod(gt_np.shape):\n",
    "    p = np.random.randint(gt_np.shape[0])\n",
    "    x = np.random.randint(gt_np.shape[1])\n",
    "    y = np.random.randint(gt_np.shape[2])\n",
    "    if (p,x,y) not in idx:\n",
    "        idx.add((p,x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_np = np.array(list(idx))\n",
    "idx_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_labels = [0]\n",
    "patch_size = 5\n",
    "\n",
    "pad_width = patch_size // 2\n",
    "\n",
    "train_np = np.pad(train_np, ((0,0), (pad_width, pad_width), (pad_width, pad_width), (0,0)))\n",
    "gt_np = np.pad(gt_np, ((0,0), (pad_width, pad_width), (pad_width, pad_width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones_like(gt_np)\n",
    "for l in ignored_labels:\n",
    "    mask[gt_np == l] = 0\n",
    "patch_labeled, x_labeled, y_labeled = np.nonzero(mask)\n",
    "\n",
    "for l in ignored_labels:\n",
    "    patch_unlabeled, x_unlabeled, y_unlabeled = np.nonzero(mask==l)\n",
    "\n",
    "p = patch_size // 2\n",
    "\n",
    "indices_labeled = np.array([(p_l, x_l, y_l) for p_l, x_l, y_l in zip(patch_labeled, x_labeled, y_labeled) if x_l >= p and x_l < train_np.shape[1] - p and y_l >= p and y_l < train_np.shape[2] - p])\n",
    "labels = [gt_np[p_l, x_l, y_l] for p_l, x_l, y_l in indices_labeled]\n",
    "\n",
    "indices_unlabeled = np.array([(p_u, x_u, y_u) for p_u, x_u, y_u in zip(patch_unlabeled, x_unlabeled, y_unlabeled) if x_u >= p and x_u < train_np.shape[1] - p and y_u >= p and y_u < train_np.shape[2] - p])\n",
    "\n",
    "indices_labeled_shuffle = np.copy(indices_labeled)\n",
    "indices_unlabeled_shuffle = np.copy(indices_unlabeled)\n",
    "\n",
    "np.random.shuffle(indices_labeled_shuffle)\n",
    "np.random.shuffle(indices_unlabeled_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, x, y = indices_labeled[0]\n",
    "\n",
    "data = train_np[p, x-pad_width:x - pad_width + patch_size, y-pad_width:y-pad_width+patch_size]\n",
    "\n",
    "label = gt_np[p, x-pad_width:x - pad_width + patch_size, y-pad_width:y-pad_width+patch_size]\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape = train_np.reshape(np.prod(train_np.shape[:3]), np.prod(train_np.shape[3:]))\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "reshape = scaler.fit_transform(reshape)\n",
    "img_list = reshape.reshape(train_np.shape)\n",
    "\n",
    "test = np.asarray(test, dtype='float32')\n",
    "data_test = test.reshape(np.prod(test.shape[:2]), np.prod(test.shape[2:]))\n",
    "data_test = scaler.transform(data_test)\n",
    "test_patch = data_test.reshape(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max((test - np.min(train_np))/(np.max(train_np) - np.min(train_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = train_np[0].shape[0]\n",
    "y_size = train_np[0].shape[1]\n",
    "data_train = np.array([train_np[p_l, x_l, y_l] for p_l, x_l, y_l in zip(patch_labeled, x_labeled, y_labeled) if x_l >= p and x_l < x_size - p and y_l >= p and y_l < y_size - p])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=11)\n",
    "pca.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nalepa_classes = np.zeros(len(label_values))\n",
    "\n",
    "for i in range(len(train_gt)):\n",
    "    for c in range(len(nalepa_classes)):\n",
    "        amount = np.count_nonzero(train_gt[i] == c)\n",
    "        nalepa_classes[c] += amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nalepa_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(nalepa_classes[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(gt_np) + np.count_nonzero(test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.pad(train_patches, ((0,0), (2,2), (2,2), (0,0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_predictions(convert_to_color(gt_5), vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_dataset(patch_5, gt_5, rgb_bands, label_values, palette, vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, gt, label_values, ignored_labels, rgb_bands, palette = get_dataset('Salinas', target_folder='/home/oscar/Desktop/Exjobb/Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "y = 0\n",
    "\n",
    "patch_list = []\n",
    "\n",
    "while y in range(img.shape[1]):\n",
    "    while x in range(img.shape[0]):\n",
    "        if y + patch_size <= img.shape[1]: \n",
    "            if x + patch_size <= img.shape[0]:\n",
    "                patch_list.append(img[x:x+patch_size, y:y+patch_size, :])\n",
    "        '''\n",
    "            else: \n",
    "                patch_list.append(img[x:, y:y+patch_size, :])\n",
    "        else:\n",
    "            if x + patch_size <= img.shape[0]:\n",
    "                patch_list.append(img[x:x+patch_size, y:, :])\n",
    "            else: \n",
    "                patch_list.append(img[x:, y:, :])\n",
    "        '''\n",
    "        x += patch_size\n",
    "    y += patch_size\n",
    "    x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "y = 0\n",
    "\n",
    "gt_list = []\n",
    "\n",
    "while y in range(gt.shape[1]):\n",
    "    while x in range(gt.shape[0]):\n",
    "        if y + patch_size <= gt.shape[1]: \n",
    "            if x + patch_size <= gt.shape[0]:\n",
    "                gt_list.append(gt[x:x+patch_size, y:y+patch_size])\n",
    "            #else: \n",
    "                #gt_list.append(gt[x:, y:y+patch_size])\n",
    "        #else:\n",
    "            #if x + patch_size <= gt.shape[0]:\n",
    "                #gt_list.append(gt[x:x+patch_size, y:])\n",
    "            #else: \n",
    "                #gt_list.append(gt[x:, y:])\n",
    "        x += patch_size\n",
    "    y += patch_size\n",
    "    x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list = []\n",
    "\n",
    "for i in range(len(gt_list)):\n",
    "    shape_list.append(np.shape(gt_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_list[1][3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_dataset(patch_list[453], gt_list[453], rgb_bands, label_values, palette, vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_predictions(convert_to_color(gt_list[453]), vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_list[453][3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = np.zeros(len(label_values))\n",
    "gt_center = np.zeros(len(gt_list))\n",
    "\n",
    "for i in range(len(gt_list)):\n",
    "    c = gt_list[i][3,3]\n",
    "    class_list[c] += 1\n",
    "    gt_center[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(class_list[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.bincount(gt_list[352].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_major_list = np.zeros(len(label_values))\n",
    "gt_major = np.zeros(len(gt_list))\n",
    "\n",
    "for i in range(len(gt_list)):\n",
    "    amount = np.bincount(gt_list[i].flatten())\n",
    "    c = np.argmax(amount)\n",
    "    class_major_list[c] += 1\n",
    "    gt_major[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_major_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(class_major_list[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_patch_data, get_pixel_idx, HyperX_patches\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import HamidaEtAl\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, train_gt, test_img, test_gt, label_values, ignored_labels, rgb_bands, palette = get_patch_data('Salinas', 5, target_folder=data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bands = train_img.shape[-1]\n",
    "n_classes = len(label_values) - len(ignored_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HamidaEtAl(n_bands, n_classes,\n",
    "                       patch_size=5)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9,\n",
    "                          nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sup, idx_val, idx_unsup = get_pixel_idx(train_img, train_gt, ignored_labels, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_gt = [train_gt[p_l, x_l, y_l] for p_l, x_l, y_l in idx_sup]\n",
    "samples_class = np.zeros(n_classes)\n",
    "for c in np.unique(train_labeled_gt):\n",
    "    samples_class[c-1] = np.count_nonzero(train_labeled_gt == c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {'patch_size': 5, 'dataset': 'Salinas', 'ignored_labels': ignored_labels, \n",
    "               'flip_augmentation': True, 'radiation_augmentation': False, 'mixture_augmentation': False,\n",
    "              'center_pixel': True, 'supervision': 'full'}\n",
    "\n",
    "val_dataset = HyperX_patches(train_img, train_gt, idx_val, labeled=True, **hyperparams)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=10)\n",
    "\n",
    "train_labeled_dataset = HyperX_patches(train_img, train_gt, idx_sup, labeled=True, **hyperparams)\n",
    "train_labeled_loader = data.DataLoader(train_labeled_dataset, batch_size=10,\n",
    "                                       #pin_memory=True, num_workers=5,\n",
    "                                       shuffle=True, drop_last=True)\n",
    "\n",
    "unlabeled_ratio = math.ceil(len(idx_unsup)/len(idx_sup))\n",
    "\n",
    "train_unlabeled_dataset = HyperX_patches(train_img, train_gt, idx_unsup, labeled=False, **hyperparams)\n",
    "train_unlabeled_loader = data.DataLoader(train_unlabeled_dataset, batch_size=10*unlabeled_ratio,\n",
    "                                       #pin_memory=True, num_workers=5,\n",
    "                                       shuffle=True, drop_last=True)\n",
    "amount_labeled = idx_sup.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "0.0010744985\n",
      "(0, 1)\n",
      "0.0010744985\n",
      "(0, 2)\n",
      "0.0010744985\n",
      "(0, 3)\n",
      "0.0010744985\n",
      "(0, 4)\n",
      "0.0010744985\n",
      "(1, 0)\n",
      "0.0010744985\n",
      "(1, 1)\n",
      "0.0010744985\n",
      "(1, 2)\n",
      "0.0010744985\n",
      "(1, 3)\n",
      "0.0010744985\n",
      "(1, 4)\n",
      "0.0010744985\n",
      "(2, 0)\n",
      "0.036891118\n",
      "(2, 1)\n",
      "0.045487106\n",
      "(2, 2)\n",
      "0.045487106\n",
      "(2, 3)\n",
      "0.0010744985\n",
      "(2, 4)\n",
      "0.0010744985\n",
      "(3, 0)\n",
      "0.027459407\n",
      "(3, 1)\n",
      "0.036055397\n",
      "(3, 2)\n",
      "0.036055397\n",
      "(3, 3)\n",
      "0.0010744985\n",
      "(3, 4)\n",
      "0.0010744985\n",
      "(4, 0)\n",
      "0.03760745\n",
      "(4, 1)\n",
      "0.03760745\n",
      "(4, 2)\n",
      "0.03760745\n",
      "(4, 3)\n",
      "0.0010744985\n",
      "(4, 4)\n",
      "0.0010744985\n"
     ]
    }
   ],
   "source": [
    "data = train_img[idx_unsup[0][0], 0:5:, 9:14]\n",
    "data_aug = np.zeros_like(data)\n",
    "data_train = data - np.mean(data, axis=(0,1,2))\n",
    "for x,y in np.ndenumerate(data[:,:,0]):\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 14, 204)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2, 12])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_unsup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt, test_gt = utils.sample_gt(gt, 0.3,\n",
    "                                        mode='disjoint')\n",
    "\n",
    "train_gt, val_gt = utils.sample_gt(train_gt, 0.95, mode='disjoint')\n",
    "\n",
    "val_dataset = HyperX(img, val_gt, labeled=True, **hyperparams)\n",
    "val_loader = data.DataLoader(val_dataset,\n",
    "                             batch_size=10)\n",
    "\n",
    "train_labeled_gt, train_unlabeled_gt = utils.sample_gt(train_gt, 1/(7 + 1),\n",
    "                                                        mode='disjoint')\n",
    "\n",
    "samples_class = np.zeros(n_classes)\n",
    "for c in np.unique(train_labeled_gt):\n",
    "    samples_class[c-1] = np.count_nonzero(train_labeled_gt == c)\n",
    "\n",
    "train_labeled_dataset = HyperX(img, train_labeled_gt, labeled=True, **hyperparams)\n",
    "train_labeled_loader = data.DataLoader(train_labeled_dataset, batch_size=10,\n",
    "                                       #pin_memory=True, num_workers=5,\n",
    "                                       shuffle=True, drop_last=True)\n",
    "\n",
    "train_unlabeled_dataset = HyperX(img, train_unlabeled_gt, labeled=False, **hyperparams)\n",
    "train_unlabeled_loader = data.DataLoader(train_unlabeled_dataset,\n",
    "                                         batch_size=10*7,\n",
    "                                         #pin_memory=True, num_workers=5,\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_labeled = []\n",
    "\n",
    "for i in range(train_labeled_dataset.__len__()):\n",
    "    samples_labeled.append(train_labeled_dataset.__getitem__(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_labeled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train = []\n",
    "\n",
    "for i in range(train_dataset.__len__()):\n",
    "    samples_train.append(train_dataset.__getitem__(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1002865"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     64809\n",
      "           1       1.00      1.00      1.00      1787\n",
      "           2       1.00      1.00      1.00      3356\n",
      "           3       1.00      1.00      1.00      1976\n",
      "           4       1.00      1.00      1.00      1394\n",
      "           5       1.00      1.00      1.00      2527\n",
      "           6       1.00      1.00      1.00      3959\n",
      "           7       1.00      1.00      1.00      3579\n",
      "           8       1.00      1.00      1.00      9860\n",
      "           9       1.00      1.00      1.00      5983\n",
      "          10       1.00      1.00      1.00      2441\n",
      "          11       1.00      1.00      1.00       968\n",
      "          12       1.00      1.00      1.00      1903\n",
      "          13       1.00      1.00      1.00       875\n",
      "          14       1.00      1.00      1.00       883\n",
      "          15       1.00      1.00      1.00      5958\n",
      "          16       1.00      1.00      1.00      1778\n",
      "\n",
      "    accuracy                           1.00    114036\n",
      "   macro avg       1.00      1.00      1.00    114036\n",
      "weighted avg       1.00      1.00      1.00    114036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_gt.flatten(), test_gt.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
