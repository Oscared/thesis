{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Datasets.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import visdom\n",
    "import ipynb.fs.full.Datasets as Datasets\n",
    "from Datasets import get_dataset, HyperX, HyperX_unlabeled\n",
    "import utils\n",
    "import numpy as np\n",
    "import sklearn.svm\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import torch.utils.data as data\n",
    "from torchsummary import summary\n",
    "\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.externals import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets = importlib.reload(Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "salinas_img, salinas_gt, salinas_label_values, salinas_ignored_labels, salinas_rgb_bands, salinas_palette = get_dataset(\"Salinas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify bands and classes while generating color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = len(salinas_label_values)\n",
    "N_BANDS = salinas_img.shape[-1]\n",
    "\n",
    "if salinas_palette is None:\n",
    "    # Generate color palette\n",
    "    salinas_palette = {0: (0, 0, 0)}\n",
    "    for k, color in enumerate(sns.color_palette(\"hls\", len(salinas_label_values) - 1)):\n",
    "        salinas_palette[k + 1] = tuple(np.asarray(255 * np.array(color), dtype='uint8'))\n",
    "invert_palette = {v: k for k, v in salinas_palette.items()}\n",
    "\n",
    "def convert_to_color(x):\n",
    "    return utils.convert_to_color_(x, palette=salinas_palette)\n",
    "def convert_from_color(x):\n",
    "    return utils.convert_from_color_(x, palette=invert_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sample percantage and sampling of data from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14925 samples selected (over 54129)\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_PERCENTAGE = 0.3\n",
    "SAMPLING_MODE = 'disjoint' #random, fixed, disjoint\n",
    "\n",
    "train_gt, test_gt = utils.sample_gt(salinas_gt, SAMPLE_PERCENTAGE, mode=SAMPLING_MODE)\n",
    "print(\"{} samples selected (over {})\".format(np.count_nonzero(train_gt), np.count_nonzero(salinas_gt)))\n",
    "\n",
    "utils.display_predictions(convert_to_color(train_gt), vis, caption=\"Train ground truth\")\n",
    "utils.display_predictions(convert_to_color(test_gt), vis, caption=\"Test ground truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a training function that uses \"FixMatch\" style training with labeled and unlabeled datasets. Configure the original training function from \"test\" to suit the pytorch implementation of FixMatch here: https://github.com/kekmodel/FixMatch-pytorch/blob/master/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, criterion, labeled_data_loader, unlabeled_data_loader, epoch, threshold, scheduler=None,\n",
    "          display_iter=100, device=torch.device('cpu'), display=None,\n",
    "          val_loader=None):\n",
    "    \"\"\"\n",
    "    Training loop to optimize a network for several epochs and a specified loss\n",
    "    Args:\n",
    "        net: a PyTorch model\n",
    "        optimizer: a PyTorch optimizer\n",
    "        labeled_data_loader: a PyTorch dataset loader for the labeled dataset\n",
    "        unlabeled_data_loader: a PyTorch dataset loader for the weakly and strongly augmented, unlabeled dataset\n",
    "        epoch: int specifying the number of training epochs\n",
    "        threshold: probability thresold for pseudo labels acceptance\n",
    "        criterion: a PyTorch-compatible loss function, e.g. nn.CrossEntropyLoss\n",
    "        device (optional): torch device to use (defaults to CPU)\n",
    "        display_iter (optional): number of iterations before refreshing the\n",
    "        display (False/None to switch off).\n",
    "        scheduler (optional): PyTorch scheduler\n",
    "        val_loader (optional): validation dataset\n",
    "        supervision (optional): 'full' or 'semi'\n",
    "    \"\"\"\n",
    "\n",
    "    if criterion is None:\n",
    "        raise Exception(\"Missing criterion. You must specify a loss function.\")\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    save_epoch = epoch // 20 if epoch > 20 else 1\n",
    "\n",
    "\n",
    "    losses = np.zeros(1000000)\n",
    "    mean_losses = np.zeros(100000000)\n",
    "    iter_ = 1\n",
    "    loss_win, val_win = None, None\n",
    "    val_accuracies = []\n",
    "\n",
    "    for e in tqdm(range(1, epoch + 1), desc=\"Training the network\"):\n",
    "        # Set the network to training mode\n",
    "        net.train()\n",
    "        avg_loss = 0.\n",
    "        \n",
    "        train_loader = zip(labeled_data_loader, unlabeled_data_loader)\n",
    "\n",
    "        # Run the training loop for one epoch\n",
    "        for batch_idx, (data_x, data_u) in tqdm(enumerate(train_loader), total=len(labeled_data_loader)):\n",
    "            # Load the data into the GPU if required\n",
    "            inputs_x, targets_x = data_x\n",
    "            inputs_u_w, inputs_u_s = data_u\n",
    "            \n",
    "            batch_size = inputs_x.shape[0]\n",
    "            \n",
    "            inputs = torch.cat((inputs_x, inputs_u_w, inputs_u_s)).to(device)\n",
    "            targets_x = targets_x.to(device)\n",
    "            logits = net(inputs)\n",
    "            logits_x = logits[:batch_size]\n",
    "            logits_u_w, logits_u_s = logits[batch_size:].chunk(2)\n",
    "            del logits\n",
    "\n",
    "            Lx = F.cross_entropy(logits_x, targets_x, reduction='mean')\n",
    "\n",
    "            pseudo_label = torch.softmax(logits_u_w.detach_(), dim=-1)\n",
    "            max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
    "            mask = max_probs.ge(threshold).float()\n",
    "\n",
    "            Lu = (F.cross_entropy(logits_u_s, targets_u,\n",
    "                              reduction='none') * mask).mean()\n",
    "\n",
    "            loss = Lx + 1 * Lu\n",
    "    \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "            losses[iter_] = loss.item()\n",
    "            mean_losses[iter_] = np.mean(losses[max(0, iter_ - 100):iter_ + 1])\n",
    "\n",
    "            if display_iter and iter_ % display_iter == 0:\n",
    "                string = 'Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'\n",
    "                string = string.format(e, epoch, batch_idx * len(data_x), len(data_x) * len(labeled_data_loader),\n",
    "                                       100. * batch_idx / len(labeled_data_loader), mean_losses[iter_])\n",
    "                update = None if loss_win is None else 'append'\n",
    "                loss_win = display.line(\n",
    "                    X=np.arange(iter_ - display_iter, iter_),\n",
    "                    Y=mean_losses[iter_ - display_iter:iter_],\n",
    "                    win=loss_win,\n",
    "                    update=update,\n",
    "                    opts={'title': \"Training loss\",\n",
    "                          'xlabel': \"Iterations\",\n",
    "                          'ylabel': \"Loss\"\n",
    "                         }\n",
    "                )\n",
    "                tqdm.write(string)\n",
    "\n",
    "                if len(val_accuracies) > 0:\n",
    "                    val_win = display.line(Y=np.array(val_accuracies),\n",
    "                                           X=np.arange(len(val_accuracies)),\n",
    "                                           win=val_win,\n",
    "                                           opts={'title': \"Validation accuracy\",\n",
    "                                                 'xlabel': \"Epochs\",\n",
    "                                                 'ylabel': \"Accuracy\"\n",
    "                                                })\n",
    "            iter_ += 1\n",
    "            del(data_x, data_u, loss)\n",
    "\n",
    "        # Update the scheduler\n",
    "        avg_loss /= len(labeled_data_loader)\n",
    "        if val_loader is not None:\n",
    "            val_acc = val(net, val_loader, device=device, supervision='full')\n",
    "            val_accuracies.append(val_acc)\n",
    "            metric = -val_acc\n",
    "        else:\n",
    "            metric = avg_loss\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(metric)\n",
    "        elif scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Save the weights\n",
    "        if e % save_epoch == 0:\n",
    "            save_model(net, utils.camel_to_snake(str(net.__class__.__name__)), \n",
    "                       labeled_data_loader.dataset.name, epoch=e, metric=abs(metric))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test, validation and saving models should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name, dataset_name, **kwargs):\n",
    "     model_dir = './checkpoints/' + model_name + \"/\" + dataset_name + \"/\"\n",
    "     if not os.path.isdir(model_dir):\n",
    "         os.makedirs(model_dir, exist_ok=True)\n",
    "     if isinstance(model, torch.nn.Module):\n",
    "         filename = str(datetime.datetime.now()) + \"_epoch{epoch}_{metric:.2f}\".format(**kwargs)\n",
    "         tqdm.write(\"Saving neural network weights in {}\".format(filename))\n",
    "         torch.save(model.state_dict(), model_dir + filename + '.pth')\n",
    "     else:\n",
    "         filename = str(datetime.datetime.now())\n",
    "         tqdm.write(\"Saving model params in {}\".format(filename))\n",
    "         joblib.dump(model, model_dir + filename + '.pkl')\n",
    "\n",
    "\n",
    "def test(net, img, hyperparams):\n",
    "    \"\"\"\n",
    "    Test a model on a specific image\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    patch_size = hyperparams['patch_size']\n",
    "    center_pixel = hyperparams['center_pixel']\n",
    "    batch_size, device = hyperparams['batch_size'], hyperparams['device']\n",
    "    n_classes = hyperparams['n_classes']\n",
    "\n",
    "    kwargs = {'step': hyperparams['test_stride'], 'window_size': (patch_size, patch_size)}\n",
    "    probs = np.zeros(img.shape[:2] + (n_classes,))\n",
    "\n",
    "    iterations = utils.count_sliding_window(img, **kwargs) // batch_size\n",
    "    for batch in tqdm(utils.grouper(batch_size, utils.sliding_window(img, **kwargs)),\n",
    "                      total=(iterations), desc=\"Inference on the image\"):\n",
    "        with torch.no_grad():\n",
    "            if patch_size == 1:\n",
    "                data = [b[0][0, 0] for b in batch]\n",
    "                data = np.copy(data)\n",
    "                data = torch.from_numpy(data)\n",
    "            else:\n",
    "                data = [b[0] for b in batch]\n",
    "                data = np.copy(data)\n",
    "                data = data.transpose(0, 3, 1, 2)\n",
    "                data = torch.from_numpy(data)\n",
    "                data = data.unsqueeze(1)\n",
    "\n",
    "            indices = [b[1:] for b in batch]\n",
    "            data = data.to(device)\n",
    "            output = net(data)\n",
    "            if isinstance(output, tuple):\n",
    "                output = output[0]\n",
    "            output = output.to('cpu')\n",
    "\n",
    "            if patch_size == 1 or center_pixel:\n",
    "                output = output.numpy()\n",
    "            else:\n",
    "                output = np.transpose(output.numpy(), (0, 2, 3, 1))\n",
    "            for (x, y, w, h), out in zip(indices, output):\n",
    "                if center_pixel:\n",
    "                    probs[x + w // 2, y + h // 2] += out\n",
    "                else:\n",
    "                    probs[x:x + w, y:y + h] += out\n",
    "    return probs\n",
    "\n",
    "def val(net, data_loader, device='cpu', supervision='full'):\n",
    "    # TODO : fix me using metrics()\n",
    "    accuracy, total = 0., 0.\n",
    "    ignored_labels = data_loader.dataset.ignored_labels\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            # Load the data into the GPU if required\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if supervision == 'full':\n",
    "                output = net(data)\n",
    "            elif supervision == 'semi':\n",
    "                outs = net(data)\n",
    "                output, rec = outs\n",
    "            _, output = torch.max(output, dim=1)\n",
    "            for out, pred in zip(output.view(-1), target.view(-1)):\n",
    "                if out.item() in ignored_labels:\n",
    "                    continue\n",
    "                else:\n",
    "                    accuracy += out.item() == pred.item()\n",
    "                    total += 1\n",
    "    return accuracy / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HamidaEtAl(nn.Module):\n",
    "    \"\"\"\n",
    "    3-D Deep Learning Approach for Remote Sensing Image Classification\n",
    "    Amina Ben Hamida, Alexandre Benoit, Patrick Lambert, Chokri Ben Amar\n",
    "    IEEE TGRS, 2018\n",
    "    https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344565\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv3d):\n",
    "            init.kaiming_normal_(m.weight)\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "    def __init__(self, input_channels, n_classes, patch_size=5, dilation=1):\n",
    "        super(HamidaEtAl, self).__init__()\n",
    "        # The first layer is a (3,3,3) kernel sized Conv characterized\n",
    "        # by a stride equal to 1 and number of neurons equal to 20\n",
    "        self.patch_size = patch_size\n",
    "        self.input_channels = input_channels\n",
    "        dilation = (dilation, 1, 1)\n",
    "\n",
    "        if patch_size == 3:\n",
    "            self.conv1 = nn.Conv3d(\n",
    "                1, 20, (3, 3, 3), stride=(1, 1, 1), dilation=dilation, padding=1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv3d(\n",
    "                1, 20, (3, 3, 3), stride=(1, 1, 1), dilation=dilation, padding=0)\n",
    "        # Next pooling is applied using a layer identical to the previous one\n",
    "        # with the difference of a 1D kernel size (1,1,3) and a larger stride\n",
    "        # equal to 2 in order to reduce the spectral dimension\n",
    "        self.pool1 = nn.Conv3d(\n",
    "            20, 20, (3, 1, 1), dilation=dilation, stride=(2, 1, 1), padding=(1, 0, 0))\n",
    "        # Then, a duplicate of the first and second layers is created with\n",
    "        # 35 hidden neurons per layer.\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            20, 35, (3, 3, 3), dilation=dilation, stride=(1, 1, 1), padding=(1, 0, 0))\n",
    "        self.pool2 = nn.Conv3d(\n",
    "            35, 35, (3, 1, 1), dilation=dilation, stride=(2, 1, 1), padding=(1, 0, 0))\n",
    "        # Finally, the 1D spatial dimension is progressively reduced\n",
    "        # thanks to the use of two Conv layers, 35 neurons each,\n",
    "        # with respective kernel sizes of (1,1,3) and (1,1,2) and strides\n",
    "        # respectively equal to (1,1,1) and (1,1,2)\n",
    "        self.conv3 = nn.Conv3d(\n",
    "            35, 35, (3, 1, 1), dilation=dilation, stride=(1, 1, 1), padding=(1, 0, 0))\n",
    "        self.conv4 = nn.Conv3d(\n",
    "            35, 35, (2, 1, 1), dilation=dilation, stride=(2, 1, 1), padding=(1, 0, 0))\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.features_size = self._get_final_flattened_size()\n",
    "        # The architecture ends with a fully connected layer where the number\n",
    "        # of neurons is equal to the number of input classes.\n",
    "        self.fc = nn.Linear(self.features_size, n_classes)\n",
    "\n",
    "        self.apply(self.weight_init)\n",
    "\n",
    "    def _get_final_flattened_size(self):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros((1, 1, self.input_channels,\n",
    "                             self.patch_size, self.patch_size))\n",
    "            x = self.pool1(self.conv1(x))\n",
    "            x = self.pool2(self.conv2(x))\n",
    "            x = self.conv3(x)\n",
    "            x = self.conv4(x)\n",
    "            _, t, c, w, h = x.size()\n",
    "        return t * c * w * h\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, self.features_size)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a cosine training scheme with warm-up. Shown to be good, taken from the same resource as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps,\n",
    "                                    num_training_steps,\n",
    "                                    num_cycles=7./16.,\n",
    "                                    last_epoch=-1):\n",
    "    def _lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        no_progress = float(current_step - num_warmup_steps) / \\\n",
    "            float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0., math.cos(math.pi * num_cycles * no_progress))\n",
    "\n",
    "    return LambdaLR(optimizer, _lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate weights and hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "hyperparams = {'patch_size' : 1, 'ignored_labels' : salinas_ignored_labels, 'flip_augmentation' : False, \n",
    "              'radiation_augmentation' : False, 'mixture_augmentation' : False, 'center_pixel' : True, \n",
    "              'supervision' : 'full', 'batch_size' : 100, 'epochs' : 100, 'dataset' : 'Salinas', \n",
    "              'n_classes' : N_CLASSES, 'test_stride' : 1, 'scheduler' : None, 'weights' : None,\n",
    "              'device' : device, 'n_bands' : N_BANDS, 'warmup' : 0, 'threshold' : 0.95}\n",
    "\n",
    "weights = torch.ones(N_CLASSES)\n",
    "weights[torch.LongTensor(salinas_ignored_labels)] = 0\n",
    "weights = weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams['patch_size'] = 5\n",
    "hyperparams['center_pixel'] = True\n",
    "hyperparams['epochs'] = 10\n",
    "hyperparams['warmup'] = 1\n",
    "hyperparams['batch_size'] = 64\n",
    "\n",
    "hyperparams['flip_augmentation'] = True\n",
    "\n",
    "model = HamidaEtAl(hyperparams['n_bands'], hyperparams['n_classes'], \n",
    "                   patch_size=hyperparams['patch_size'])\n",
    "lr =  0.03\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True)\n",
    "loss = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6235 samples selected (over 11870)\n",
      "1609 samples selected (over 6235)\n",
      "4626 samples selected (over 6235)\n"
     ]
    }
   ],
   "source": [
    "prev_train_gt = train_gt\n",
    "\n",
    "train_gt, val_gt = utils.sample_gt(prev_train_gt, 0.95, mode=SAMPLING_MODE)\n",
    "print(\"{} samples selected (over {})\".format(np.count_nonzero(train_gt), np.count_nonzero(prev_train_gt)))\n",
    "\n",
    "val_dataset = HyperX(salinas_img, val_gt, **hyperparams)\n",
    "val_loader = data.DataLoader(val_dataset,\n",
    "                             batch_size=hyperparams['batch_size'])\n",
    "\n",
    "samples = np.count_nonzero(train_gt)\n",
    "unlabeled_portion = 7\n",
    "\n",
    "train_labeled_gt, train_unlabeled_gt = utils.sample_gt(train_gt, 1/(unlabeled_portion + 1), mode=SAMPLING_MODE)\n",
    "print(\"{} samples selected (over {})\".format(np.count_nonzero(train_labeled_gt), np.count_nonzero(train_gt)))\n",
    "print(\"{} samples selected (over {})\".format(np.count_nonzero(train_unlabeled_gt), np.count_nonzero(train_gt)))\n",
    "\n",
    "train_labeled_dataset = HyperX(salinas_img, train_labeled_gt, **hyperparams)\n",
    "train_labeled_loader = data.DataLoader(train_labeled_dataset, batch_size=hyperparams['batch_size'],\n",
    "                               shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "train_unlabeled_dataset = HyperX_unlabeled(salinas_img, train_unlabeled_gt, **hyperparams)\n",
    "train_unlabeled_loader = data.DataLoader(train_unlabeled_dataset, \n",
    "                                         batch_size=hyperparams['batch_size']*unlabeled_portion,\n",
    "                                         shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "amount_labeled = samples//(unlabeled_portion + 1)\n",
    "\n",
    "iterations = amount_labeled // hyperparams['batch_size']\n",
    "total_steps = iterations * hyperparams['epochs']\n",
    "hyperparams['scheduler'] = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                           hyperparams['warmup']*iterations, total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = next(iter(train_labeled_loader))\n",
    "out = model(output[0])\n",
    "out_w, out_s = (out).chunk(2)\n",
    "ps_lb = torch.softmax(out_w.detach_(), dim=-1)\n",
    "probs, target = torch.max(ps_lb, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out_eval = model(output[0])\n",
    "    out_eval.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_1, part_2 = utils.sample_gt(salinas_gt, 0.1, mode='better_disjoint')\n",
    "utils.display_predictions(convert_to_color(part_1), vis, caption=\"Part 1 ground truth\")\n",
    "utils.display_predictions(convert_to_color(part_2), vis, caption=\"Part 2 ground truth\")\n",
    "part_3, part_4 = utils.sample_gt(part_1, 0.1, mode='better_disjoint')\n",
    "utils.display_predictions(convert_to_color(part_3), vis, caption=\"Part 3 ground truth\")\n",
    "utils.display_predictions(convert_to_color(part_4), vis, caption=\"Part 4 ground truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(part_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_predictions(convert_to_color(train_labeled_gt), vis, caption=\"Labeled train ground truth\")\n",
    "utils.display_predictions(convert_to_color(train_unlabeled_gt), vis, caption=\"Unlabeled train ground truth\")\n",
    "utils.display_predictions(convert_to_color(val_gt), vis, caption=\"Validation ground truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_BALANCING = True\n",
    "\n",
    "if CLASS_BALANCING:\n",
    "    weights_balance = utils.compute_imf_weights(train_gt, hyperparams['n_classes'], salinas_ignored_labels)\n",
    "    hyperparams['weights'] = torch.from_numpy(weights_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.1592, 0.6362, 1.1571, 1.7005, 0.8805, 0.5990, 0.6537, 0.2072,\n",
       "        0.3814, 0.7082, 2.1271, 1.2069, 2.4884, 2.1700, 0.3205, 1.2588],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training the network:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patch_size': 5, 'ignored_labels': [0], 'flip_augmentation': True, 'radiation_augmentation': False, 'mixture_augmentation': False, 'center_pixel': True, 'supervision': 'full', 'batch_size': 64, 'epochs': 10, 'dataset': 'Salinas', 'n_classes': 17, 'test_stride': 1, 'scheduler': <torch.optim.lr_scheduler.LambdaLR object at 0x7faa4fa47a10>, 'weights': tensor([0.0000, 0.7640, 0.8997, 0.8341, 2.4965, 1.3377, 0.8501, 0.9530, 0.3093,\n",
      "        0.5086, 1.0519, 1.5413, 1.7126, 3.6927, 3.2824, 0.4758, 1.8658],\n",
      "       dtype=torch.float64), 'device': device(type='cpu'), 'n_bands': 204, 'warmup': 1, 'threshold': 0.95}\n",
      "Network :\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 20, 202, 3, 3]             560\n",
      "            Conv3d-2        [-1, 20, 101, 3, 3]           1,220\n",
      "            Conv3d-3        [-1, 35, 101, 1, 1]          18,935\n",
      "            Conv3d-4         [-1, 35, 51, 1, 1]           3,710\n",
      "            Conv3d-5         [-1, 35, 51, 1, 1]           3,710\n",
      "            Conv3d-6         [-1, 35, 26, 1, 1]           2,485\n",
      "           Dropout-7                  [-1, 910]               0\n",
      "            Linear-8                   [-1, 17]          15,487\n",
      "================================================================\n",
      "Total params: 46,107\n",
      "Trainable params: 46,107\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.48\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 0.68\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:10<03:43, 10.65s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:20<03:30, 10.53s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:30<03:16, 10.36s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:40<03:02, 10.12s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:51<02:55, 10.33s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [01:00<02:41, 10.06s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:10<02:30, 10.00s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:20<02:20, 10.02s/it]\u001b[A\n",
      " 41%|████      | 9/22 [01:30<02:09,  9.93s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:40<02:00, 10.01s/it]\u001b[A\n",
      "Training the network:  10%|█         | 1/10 [01:47<16:09, 107.68s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:32:09.692558_epoch1_0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:10<03:37, 10.38s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:20<03:27, 10.39s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:31<03:16, 10.35s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:41<03:06, 10.38s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:52<02:57, 10.46s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [01:01<02:43, 10.24s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:11<02:32, 10.16s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:21<02:18,  9.92s/it]\u001b[A\n",
      " 41%|████      | 9/22 [01:30<02:07,  9.79s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:40<02:00, 10.08s/it]\u001b[A\n",
      "Training the network:  20%|██        | 2/10 [03:36<14:23, 107.95s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:33:58.277503_epoch2_0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:09<03:29,  9.96s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:20<03:22, 10.11s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:30<03:12, 10.12s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:40<03:00, 10.04s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:50<02:48,  9.91s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [00:59<02:37,  9.85s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:09<02:26,  9.77s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:19<02:17,  9.81s/it]\u001b[A\n",
      " 41%|████      | 9/22 [01:29<02:08,  9.91s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:39<01:59,  9.97s/it]\u001b[A\n",
      "Training the network:  30%|███       | 3/10 [05:24<12:35, 107.89s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:35:46.016682_epoch3_0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:09<03:22,  9.66s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:19<03:16,  9.82s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:30<03:08,  9.92s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:40<03:01, 10.08s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:50<02:52, 10.13s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [01:00<02:42, 10.13s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:11<02:32, 10.19s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:21<02:21, 10.14s/it]\u001b[A\n",
      " 41%|████      | 9/22 [01:30<02:08,  9.90s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:39<01:59,  9.98s/it]\u001b[A\n",
      "Training the network:  40%|████      | 4/10 [07:11<10:46, 107.71s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:37:33.301173_epoch4_0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:09<03:22,  9.64s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:19<03:14,  9.70s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:29<03:03,  9.65s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:38<02:51,  9.55s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:47<02:41,  9.51s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [00:57<02:32,  9.53s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:06<02:22,  9.48s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:16<02:13,  9.50s/it]\u001b[A\n",
      " 41%|████      | 9/22 [01:26<02:05,  9.62s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:35<01:55,  9.59s/it]\u001b[A\n",
      "Training the network:  50%|█████     | 5/10 [08:54<08:52, 106.45s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:39:16.811619_epoch5_0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:09<03:18,  9.45s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:18<03:08,  9.43s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:28<02:59,  9.44s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:38<02:52,  9.60s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:47<02:42,  9.55s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [00:57<02:31,  9.49s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:06<02:23,  9.60s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:16<02:13,  9.54s/it]\u001b[A\n",
      " 41%|████      | 9/22 [01:26<02:05,  9.65s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:36<01:55,  9.62s/it]\u001b[A\n",
      "Training the network:  60%|██████    | 6/10 [10:39<07:03, 105.80s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:41:01.089682_epoch6_0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:09<03:24,  9.72s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:19<03:13,  9.68s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:28<03:02,  9.61s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:38<02:53,  9.66s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:48<02:45,  9.71s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [00:58<02:36,  9.78s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:08<02:27,  9.82s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:17<02:16,  9.76s/it]\u001b[A\n",
      " 41%|████      | 9/22 [01:27<02:07,  9.78s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:37<01:56,  9.73s/it]\u001b[A\n",
      "Training the network:  70%|███████   | 7/10 [12:25<05:17, 105.91s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:42:47.253482_epoch7_0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:09<03:23,  9.71s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:19<03:14,  9.71s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:28<03:03,  9.65s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:38<02:53,  9.64s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:48<02:47,  9.85s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [00:59<02:39,  9.99s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:09<02:32, 10.14s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:19<02:21, 10.08s/it]\u001b[A\n",
      " 41%|████      | 9/22 [01:29<02:08,  9.91s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:38<01:58,  9.89s/it]\u001b[A\n",
      "Training the network:  80%|████████  | 8/10 [14:12<03:32, 106.19s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:44:34.113611_epoch8_0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:11<03:59, 11.39s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:23<03:54, 11.71s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:34<03:35, 11.33s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:44<03:19, 11.06s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:54<03:02, 10.73s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [01:04<02:46, 10.41s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:15<02:38, 10.54s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:26<02:29, 10.68s/it]\u001b[A\n",
      " 41%|████      | 9/22 [01:35<02:14, 10.31s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:45<02:06, 10.51s/it]\u001b[A\n",
      "Training the network:  90%|█████████ | 9/10 [16:04<01:48, 108.09s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:46:26.634661_epoch9_0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:09<03:24,  9.72s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:19<03:14,  9.72s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [00:28<03:03,  9.64s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:38<02:54,  9.71s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [00:48<02:47,  9.83s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [00:58<02:37,  9.85s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [01:09<02:31, 10.10s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [01:19<02:19,  9.96s/it]\u001b[A\n",
      "                                                                     \n",
      "Training the network:  90%|█████████ | 9/10 [17:44<01:48, 108.09s/it]\n",
      " 41%|████      | 9/22 [01:39<02:11, 10.14s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [01:39<01:59,  9.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 10/10) [18/44 (41%)]\tLoss: 2.252536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training the network: 100%|██████████| 10/10 [17:51<00:00, 107.18s/it]\n",
      "Inference on the image:   0%|          | 0/1679 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving neural network weights in 2020-06-03 11:48:13.773102_epoch10_0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on the image: 1680it [02:27, 11.41it/s]                          \n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT = None #checkpoint to load weights from, string from where to load model\n",
    "\n",
    "print(hyperparams)\n",
    "print(\"Network :\")\n",
    "with torch.no_grad():\n",
    "    for input, _ in train_labeled_loader:\n",
    "        break\n",
    "    summary(model.to(hyperparams['device']), input.size()[1:])\n",
    "    # We would like to use device=hyperparams['device'] altough we have\n",
    "    # to wait for torchsummary to be fixed first.\n",
    "\n",
    "if CHECKPOINT is not None:\n",
    "    model.load_state_dict(torch.load(CHECKPOINT))\n",
    "\n",
    "try:\n",
    "    train(model, optimizer, loss, train_labeled_loader, train_unlabeled_loader, hyperparams['epochs'], \n",
    "          scheduler=hyperparams['scheduler'], device=hyperparams['device'], threshold=hyperparams['threshold'],\n",
    "          val_loader=val_loader, display=vis)\n",
    "except KeyboardInterrupt:\n",
    "    # Allow the user to stop the training\n",
    "    pass\n",
    "\n",
    "probabilities = test(model, salinas_img, hyperparams)\n",
    "prediction = np.argmax(probabilities, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix :\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [  64    0    0    0    0    0 1481    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0 2920    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0 1347  204    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0  894  195    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0   13 2093    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0 3103    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0    0 2799    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [ 114    0    0    0    0    3 8677    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   0    0    0    0    0 4791   24    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [  57    0    0    0    0 1268 1224    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [  21    0    0    0    0  805   12    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [  37    0    0    0    0 1196  280    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [  15    0    0    0    0    0  701    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [  19    0    0    0    0    0  823    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [ 185    0    0    0    0    0 5492    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [ 126    0    0    0    0    0 1276    0    0    0    0    0    0    0\n",
      "     0    0    0]]---\n",
      "Accuracy : 7.374%\n",
      "---\n",
      "F1 scores :\n",
      "\tUndefined: 0.000\n",
      "\tBrocoli_green_weeds_1: 0.000\n",
      "\tBrocoli_green_weeds_2: 0.000\n",
      "\tFallow: 0.000\n",
      "\tFallow_rough_plow: 0.000\n",
      "\tFallow_smooth: 0.002\n",
      "\tStubble: 0.180\n",
      "\tCelery: 0.000\n",
      "\tGrapes_untrained: 0.000\n",
      "\tSoil_vinyard_develop: 0.000\n",
      "\tCorn_senesced_green_weeds: 0.000\n",
      "\tLettuce_romaine_4wk: 0.000\n",
      "\tLettuce_romaine_5wk: 0.000\n",
      "\tLettuce_romaine_6wk: 0.000\n",
      "\tLettuce_romaine_7wk: 0.000\n",
      "\tVinyard_untrained: 0.000\n",
      "\tVinyard_vertical_trellis: 0.000\n",
      "---\n",
      "Kappa: 0.008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_results = utils.metrics(prediction, test_gt, ignored_labels=hyperparams['ignored_labels'], n_classes=hyperparams['n_classes'])\n",
    "\n",
    "mask = np.zeros(salinas_gt.shape, dtype='bool')\n",
    "for l in hyperparams['ignored_labels']:\n",
    "    mask[salinas_gt == l] = True\n",
    "prediction[mask] = 0\n",
    "\n",
    "color_prediction = convert_to_color(prediction)\n",
    "utils.display_predictions(color_prediction, vis, gt=convert_to_color(test_gt), caption=\"Prediction vs. test ground truth\")\n",
    "\n",
    "utils.show_results(run_results, vis, label_values=salinas_label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MixUp Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for data augmentation for mixup according to implementation at https://github.com/facebookresearch/mixup-cifar10/blob/master/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0, use_cuda=False):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training function that implements mixup augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
